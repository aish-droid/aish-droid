---
title: "code"
output:
  pdf_document: default
  html_document: default
date: "2025-03-28"
---
```{r}
setwd("C:\\Users\\Aishwarya Venkat\\Documents\\Yale\\Multivariate Statistics\\HW 5 Cluster Analysis")

```


```{r}
par(ask=FALSE)
#load relevant libraries
library(aplpack)
library(fpc)
library(cluster)
library(ape)
library(amap)
library(dplyr)
```

```{r}
#read in data from online location
firm <- read.csv("firm.csv",header=T)

head(firm)
```
```{r}
# Convert region numeric values to meaningful labels
firm$region <- factor(firm$region, 
                      levels = 1:9, 
                      labels = c("Tezpur", "Mumbai", "Hyderabad", "Surat", "Jaipur", 
                                 "Kochi", "Varanasi", "Ludhiana", "Sehore"))
```

```{r}
firm_aggregated <- firm %>%
  group_by(region) %>%
  summarise(across(electricity:labor,mean, na.rm = TRUE))

# Convert to matrix for faces() function
firm_aggregated_numeric <- as.matrix(firm_aggregated[, -1]) 

# faces plot
faces(firm_aggregated_numeric, labels = firm_aggregated$region)
```

```{r}
labels_region <- as.character(firm_aggregated$region)
stars(firm_aggregated_numeric, labels = labels_region, main = "Star Plot of Obstacles by Region")
stars(firm_aggregated_numeric, labels = labels_region, main = "Star Plot of Obstacles by Region", draw.segments = T)
```
```{r}
# Create a new dataframe 'hyd' for region 3 (Hyderabad)
hyd <- firm %>% filter(region == "Hyderabad")
head(hyd)

```
```{r}
rownames(hyd) <- hyd[, 1]
#average linkage and manhattan distance
#Get distance matrix
hyd.dist1 <- dist(hyd[, -4], method = "manhattan")

#Perform cluster analysis
hyd.clust1 <- hclust(hyd.dist1, method="average")

#Make dendrogram
hyd.clust1$labels <- as.character(hyd[, 1])
plot(hyd.clust1, xlab = "",ylab = "Distance", main = "Clustering for Hyd firms (Manhattan - average)",cex=0.35)
#identify ten groups
rect.hclust(hyd.clust1, k = 10)
```
```{r}
#get membership vector (which firm is in which group)
cuts1 <- cutree(hyd.clust1, k = 10)
cuts1

#Get list of firms in each group.  Note that group numbering is arbitrary. There is no ordering of groups
for (i in 1:10){
  print(paste("Firms in Cluster ",i))
  print(rownames(hyd)[cuts1 == i])
  print (" ")
}
```
```{r}
#ward's method and euclidean distance
#Get distance matrix
hyd.dist2 <- dist(hyd[, -4], method = "euclidean")

#Perform cluster analysis
hyd.clust2 <- hclust(hyd.dist2,method="ward.D")

#Make dendrogram
hyd.clust2$labels <- as.character(hyd[, 1])
plot(hyd.clust2, xlab = "",ylab = "Distance", main = "Clustering for Hyd firms (Euclidean - Ward)",cex=0.35)
#identify ten groups
rect.hclust(hyd.clust2, k = 10)

#get membership vector (which firm is in which group)
cuts2 <- cutree(hyd.clust2, k = 10)
cuts2

#Get list of firms in each group.  Note that group numbering is arbitrary. There is no ordering of groups
for (i in 1:10){
  print(paste("Firms in Cluster ",i))
  print(rownames(hyd)[cuts2 == i])
  print (" ")
}

```
```{r}
#complete linkage and manhattan distance
#Get distance matrix
hyd.dist3 <- dist(hyd[, -4], method = "manhattan")

#Perform cluster analysis
hyd.clust3 <- hclust(hyd.dist3,method="complete")

#Make dendrogram
hyd.clust3$labels <- as.character(hyd[, 1])
plot(hyd.clust3, xlab = "",ylab = "Distance", main = "Clustering for Hyd firms (Manhattan - complete linkage)",cex=0.35)
#identify ten groups
rect.hclust(hyd.clust3, k = 10)

#get membership vector (which firm is in which group)
cuts3 <- cutree(hyd.clust3, k = 10)
cuts3

#Get list of firms in each group.  Note that group numbering is arbitrary. There is no ordering of groups
for (i in 1:10){
  print(paste("Firms in Cluster ",i))
  print(rownames(hyd)[cuts3 == i])
  print (" ")
}
```

```{r}
hyd_obs <- hyd %>% select(-c(1:4))
source("https://raw.githubusercontent.com/jreuning/sds363_code/refs/heads/main/HClusEval3.R.txt")
#Call the function
hclus_eval(hyd_obs, dist_m = 'manhattan', clus_m = 'average', plot_op = T, print_num = 15)
hclus_eval(hyd_obs, dist_m = 'euclidean', clus_m = 'ward', plot_op = T, print_num = 15)
hclus_eval(hyd_obs, dist_m = 'manhattan', clus_m = 'complete', plot_op = T, print_num = 15)
```
### Modified Script by [Matt Peeples](https://github.com/mpeeples2008/Kmeans)

Produces screeplot like diagram with randomized comparison based on randomization within columns (i.e. as if points had been randomly assigned data values, one from each column.  Keeps total internal SS the same.

```{r}
# Set dataset to 'hyd_obs'
# Ensure kdata is in matrix format
kdata <- as.matrix(hyd_obs)  
n.lev <- 15  

# Calculate the within groups sum of squared error (SSE) for the number of cluster solutions
wss <- rnorm(10)
while (prod(wss == sort(wss, decreasing = T)) == 0) {
  wss <- (nrow(kdata) - 1) * sum(apply(kdata, 2, var))
  for (i in 2:n.lev) wss[i] <- sum(kmeans(kdata, centers = i)$withinss)
}

# Function to calculate within groups SSE for 250 randomized data sets
k.rand <- function(x) {
  km.rand <- apply(x, 2, sample)  # Ensures the same structure is preserved
  rand.wss <- (dim(x)[1] - 1) * sum(apply(km.rand, 2, var))
  for (i in 2:n.lev) rand.wss[i] <- sum(kmeans(km.rand, centers = i)$withinss)
  return(as.matrix(rand.wss))
}

rand.mat <- matrix(0, n.lev, 250)

k.1 <- function(x) { 
  for (i in 1:250) {
    r.mat <- as.matrix(suppressWarnings(k.rand(kdata)))
    rand.mat[, i] <- r.mat
  }
  return(rand.mat)
}

# Function for datasets with <3 variables
k.2.rand <- function(x) {
  km.rand <- apply(x, 2, sample)
  rand.wss <- (dim(x)[1] - 1) * sum(apply(km.rand, 2, var))
  for (i in 2:n.lev) rand.wss[i] <- sum(kmeans(km.rand, centers = i)$withinss)
  return(as.matrix(rand.wss))
}

k.2 <- function(x) {
  for (i in 1:250) {
    r.1 <- k.2.rand(kdata)
    rand.mat[, i] <- r.1
  }
  return(rand.mat)
}

# Determine if the dataset has > or < 3 variables and call appropriate function
if (dim(kdata)[2] == 2) { 
  rand.mat <- k.2(kdata) 
} else { 
  rand.mat <- k.1(kdata) 
}

# Plot within-group SSE against tested cluster solutions (Normal scale)
xrange <- range(1:n.lev)
yrange <- range(rand.mat, wss)
plot(xrange, yrange, type = 'n', xlab = "Cluster Solution", ylab = "Within Groups SSE", main = "Cluster Solutions vs SSE")
for (i in 1:250) lines(rand.mat[, i], type = 'l', col = 'red')
lines(1:n.lev, wss, type = "b", col = 'blue')
legend('topright', c('Actual Data', '250 Random Runs'), col = c('blue', 'red'), lty = 1)

# Calculate mean and standard deviation of difference between actual SSE and 250 randomized datasets
r.sse <- matrix(0, dim(rand.mat)[1], dim(rand.mat)[2])
wss.1 <- as.matrix(wss)
for (i in 1:dim(r.sse)[2]) {
  r.temp <- abs(rand.mat[, i] - wss.1[, 1])
  r.sse[, i] <- r.temp
}
r.sse.m <- apply(r.sse, 1, mean)
r.sse.sd <- apply(r.sse, 1, sd)
r.sse.plus <- r.sse.m + r.sse.sd
r.sse.min <- r.sse.m - r.sse.sd

# Plot difference between actual SSE and mean SSE from 250 randomized datasets (Normal scale)
xrange <- range(1:n.lev)
yrange <- range(r.sse.plus, r.sse.min)
plot(xrange, yrange, type = 'n', xlab = 'Cluster Solution', ylab = 'SSE - Random SSE', main = 'Cluster Solutions vs (SSE - Random SSE)')
lines(r.sse.m, type = "b", col = 'blue')
lines(r.sse.plus, type = 'l', col = 'red')
lines(r.sse.min, type = 'l', col = 'red')
legend('topright', c('SSE - random SSE', 'SD of SSE-random SSE'), col = c('blue', 'red'), lty = 1)


```
```{r}
# Choose number of clusters 
clust.level <- 5
# Apply K-means clustering and export results
fit <- kmeans(kdata, clust.level)
aggregate(kdata, by = list(fit$cluster), FUN = mean)
clust.out <- fit$cluster
kclust <- as.matrix(clust.out)
kclust.out <- cbind(kclust, hyd_obs)  # Ensure hyd_obs is used in the final output
write.table(kclust.out, file = "kmeans_out.csv", sep = ",")

rownames(kdata) <- hyd[, 1]

# Display Principal Components plot of data with clusters identified

clusplot(kdata, fit$cluster, shade = F, labels = 2, lines = 0, color = T, lty = 4, main = 'Principal Components plot showing K-means clusters',cex=0.4)


#Make plot of five cluster solution in space desginated by first two
#  two discriminant functions

plotcluster(kdata, fit$cluster, main="Five Cluster Solution in DA Space",
            xlab="First Discriminant Function", ylab="Second Discriminant Function")
```
```{r}
# Add cluster information to the original data
clustered_data <- data.frame(Firm = rownames(kdata), Cluster = fit$cluster)

# Print the list of firms for each cluster
for (i in 1:clust.level) {
  cat("\nCluster", i, ":\n")
  print(clustered_data[clustered_data$Cluster == i, "Firm"])
}
```


